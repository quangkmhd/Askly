import gradio as gr
import os
import json
import shutil
import numpy as np
from pathlib import Path
from datetime import datetime

from rag_pipeline import RAGPipeline
from processors.pdf_processor import PDFProcessor
from config.config import UPLOADED_PDFS_DIR, EMBEDDINGS_INDEX_FILE, EMBEDDINGS_DATA_FILE, TEXT_CHUNKS_FILE

# --- Global RAG Pipeline Instance ---
# Kh·ªüi t·∫°o pipeline m·ªôt l·∫ßn v√† t√°i s·ª≠ d·ª•ng n√≥
rag_pipeline = RAGPipeline()

def check_data_exists():
    """Ki·ªÉm tra xem c√≥ d·ªØ li·ªáu n√†o ƒë·ªÉ t·∫£i kh√¥ng"""
    return (EMBEDDINGS_INDEX_FILE.exists() and
            EMBEDDINGS_DATA_FILE.exists() and
            TEXT_CHUNKS_FILE.exists())

def load_existing_data():
    """T·∫£i embeddings v√† text chunks hi·ªán c√≥ n·∫øu c√≥"""
    try:
        if check_data_exists():
            embeddings_data = np.load(EMBEDDINGS_DATA_FILE, allow_pickle=True)
            embeddings = np.array(embeddings_data['embeddings'], dtype=np.float32)
            with open(TEXT_CHUNKS_FILE, 'r', encoding='utf-8') as f:
                text_chunks = json.load(f)
            with open(EMBEDDINGS_INDEX_FILE, 'r', encoding='utf-8') as f:
                embeddings_index = json.load(f)
            return embeddings, text_chunks, embeddings_index
    except Exception as e:
        print(f"L·ªói khi t·∫£i d·ªØ li·ªáu hi·ªán c√≥: {e}")
    return None, None, {}

def save_data(embeddings, text_chunks, embeddings_index):
    """L∆∞u embeddings v√† text chunks v√†o ƒëƒ©a"""
    try:
        EMBEDDINGS_DIR = EMBEDDINGS_DATA_FILE.parent
        EMBEDDINGS_DIR.mkdir(parents=True, exist_ok=True)
        if not isinstance(embeddings, np.ndarray):
            embeddings = np.array(embeddings, dtype=np.float32)
        np.savez_compressed(EMBEDDINGS_DATA_FILE, embeddings=embeddings)
        with open(TEXT_CHUNKS_FILE, 'w', encoding='utf-8') as f:
            json.dump(text_chunks, f, ensure_ascii=False, indent=2)
        with open(EMBEDDINGS_INDEX_FILE, 'w', encoding='utf-8') as f:
            json.dump(embeddings_index, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"L·ªói khi l∆∞u d·ªØ li·ªáu: {e}")
        raise

def initialize_pipeline():
    """Kh·ªüi t·∫°o ho·∫∑c t·∫£i pipeline RAG"""
    global rag_pipeline
    if not rag_pipeline.is_initialized and check_data_exists():
        print("ƒêang t·∫£i d·ªØ li·ªáu hi·ªán c√≥ v√†o pipeline...")
        try:
            embeddings, text_chunks, _ = load_existing_data()
            if embeddings is not None and text_chunks is not None:
                rag_pipeline.embeddings = embeddings
                rag_pipeline.text_chunks = text_chunks
                rag_pipeline.setup_pipeline(load_existing_embeddings=True)
                print("Pipeline ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng v·ªõi d·ªØ li·ªáu hi·ªán c√≥.")
        except Exception as e:
            print(f"L·ªói khi kh·ªüi t·∫°o pipeline: {e}")

def add_pdf_and_process(file_obj):
    """X·ª≠ l√Ω t·ªáp PDF ƒë∆∞·ª£c t·∫£i l√™n v√† c·∫≠p nh·∫≠t pipeline RAG"""
    if file_obj is None:
        return "Vui l√≤ng ch·ªçn m·ªôt t·ªáp PDF.", ""

    original_name = os.path.basename(file_obj.name)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_filename = original_name.replace(" ", "_")
    pdf_filename = f"{timestamp}_{safe_filename}"
    pdf_path = UPLOADED_PDFS_DIR / pdf_filename

    try:
        UPLOADED_PDFS_DIR.mkdir(parents=True, exist_ok=True)
        shutil.copy(file_obj.name, pdf_path)

        # ƒê·∫£m b·∫£o pipeline ƒë∆∞·ª£c kh·ªüi t·∫°o
        if not rag_pipeline.is_initialized:
            rag_pipeline.setup_pipeline(load_existing_embeddings=True)

        # X·ª≠ l√Ω PDF m·ªõi v√† th√™m v√†o kho ki·∫øn th·ª©c
        pdf_processor = PDFProcessor(pdf_path)
        pages_and_texts = pdf_processor.process_pdf()
        text_chunks = rag_pipeline.text_processor.process_text(pages_and_texts)
        new_embeddings = rag_pipeline.embedding_manager.create_embeddings(text_chunks)

        embeddings, _, embeddings_index = load_existing_data()

        if embeddings is not None and len(embeddings) > 0:
            combined_embeddings = np.vstack([embeddings, new_embeddings])
            rag_pipeline.text_chunks.extend(text_chunks)
        else:
            combined_embeddings = new_embeddings
            rag_pipeline.text_chunks = text_chunks

        rag_pipeline.embeddings = combined_embeddings
        rag_pipeline.retrieval_system.update_embeddings(rag_pipeline.embeddings, rag_pipeline.text_chunks)

        embeddings_index[str(pdf_path)] = {'original_name': original_name, 'timestamp': timestamp}
        save_data(rag_pipeline.embeddings, rag_pipeline.text_chunks, embeddings_index)

        return f"PDF '{original_name}' ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω th√†nh c√¥ng!", get_loaded_documents_list()

    except Exception as e:
        if pdf_path.exists():
            pdf_path.unlink()
        return f"L·ªói khi x·ª≠ l√Ω PDF: {str(e)}", get_loaded_documents_list()

def respond(message, chat_history):
    """T·∫°o ph·∫£n h·ªìi cho tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng"""
    if not rag_pipeline.is_initialized:
        return "", chat_history + [[message, "H·ªá th·ªëng ch∆∞a s·∫µn s√†ng. Vui l√≤ng t·∫£i l√™n t√†i li·ªáu PDF."]]
    
    try:
        answer = rag_pipeline.ask(message)
        chat_history.append((message, answer))
        return "", chat_history
    except Exception as e:
        error_message = f"L·ªói: {str(e)}"
        chat_history.append((message, error_message))
        return "", chat_history

def get_loaded_documents_list():
    """L·∫•y danh s√°ch c√°c t√†i li·ªáu ƒë√£ ƒë∆∞·ª£c t·∫£i v√† x·ª≠ l√Ω"""
    _, _, embeddings_index = load_existing_data()
    if not embeddings_index:
        return "Ch∆∞a c√≥ t√†i li·ªáu n√†o ƒë∆∞·ª£c t·∫£i l√™n."
    
    doc_list = []
    for info in embeddings_index.values():
        doc_list.append(f"üìÑ {info['original_name']} (Th√™m v√†o: {info['timestamp']})")
    return "\n".join(doc_list)

# --- Giao di·ªán Gradio ---
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# RAG Chatbot v·ªõi Gradio")
    
    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("### T·∫£i l√™n t√†i li·ªáu PDF")
            file_output = gr.Textbox(label="Tr·∫°ng th√°i x·ª≠ l√Ω", interactive=False)
            pdf_upload = gr.File(label="T·∫£i l√™n PDF", file_types=[".pdf"])
            
            gr.Markdown("### T√†i li·ªáu ƒë√£ t·∫£i")
            loaded_docs = gr.Textbox(value=get_loaded_documents_list, label="Danh s√°ch t√†i li·ªáu", interactive=False, lines=10)
            
            pdf_upload.upload(add_pdf_and_process, inputs=[pdf_upload], outputs=[file_output, loaded_docs])

        with gr.Column(scale=2):
            chatbot = gr.Chatbot(label="Chat")
            msg = gr.Textbox(label="Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n", placeholder="H·ªèi b·∫•t c·ª© ƒëi·ªÅu g√¨ v·ªÅ t√†i li·ªáu c·ªßa b·∫°n...")
            clear = gr.ClearButton([msg, chatbot])

            msg.submit(respond, [msg, chatbot], [msg, chatbot])

if __name__ == "__main__":
    initialize_pipeline()
    demo.launch(share=True)